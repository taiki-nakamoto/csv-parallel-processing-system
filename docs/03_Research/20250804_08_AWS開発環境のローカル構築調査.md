# AWS開発環境のローカル構築調査

## 1. ドキュメント情報

| 項目 | 内容 |
|------|------|
| ドキュメント名 | AWS開発環境のローカル構築調査 |
| バージョン | 1.0 |
| 作成日 | 2025-08-04 |
| 作成者 | システム開発チーム |
| 調査目的 | Dockerを使わないローカル開発環境の代替手段調査 |

## 2. 調査概要

CSVファイル並列処理システムのローカル開発環境において、Dockerを使用せずに以下のAWSサービスを代替する手段を調査しました。

### 2.1 対象サービス
- S3（ファイルストレージ）
- DynamoDB（NoSQLデータベース）
- Aurora（RDBMSデータベース）
- Lambda（サーバーレス関数）
- Step Functions（ワークフロー管理）

## 3. 各サービスの代替手段

### 3.1 S3の代替手段

| 代替手段 | 概要 | メリット | デメリット | 推奨度 |
|----------|------|----------|-----------|---------|
| **ローカルファイルシステム** | プロジェクト内にディレクトリ作成 | - 設定不要<br>- 高速<br>- デバッグ容易 | - S3 APIと互換性なし<br>- 本番環境との差異 | ⭐⭐⭐ |
| **MinIO（バイナリ版）** | S3互換オブジェクトストレージ | - S3 API完全互換<br>- Docker不要<br>- 本番環境に近い | - 別途インストール必要<br>- 設定が必要 | ⭐⭐⭐⭐⭐ |
| **AWS S3（実環境）** | 開発用S3バケット使用 | - 完全互換<br>- 設定不要 | - ネットワーク必要<br>- コスト発生 | ⭐⭐⭐⭐ |

#### 推奨実装方針
```
local-s3/
├── input-files/     # 入力CSVファイル
├── processed-files/ # 処理済みファイル
└── error-files/     # エラーファイル
```

### 3.2 DynamoDBの代替手段

| 代替手段 | 概要 | メリット | デメリット | 推奨度 |
|----------|------|----------|-----------|---------|
| **DynamoDB Local（JAR版）** | AWSが提供するローカル版 | - 完全互換<br>- Docker不要 | - Java Runtime必要<br>- メモリ使用量大 | ⭐⭐⭐⭐⭐ |
| **SQLite + アプリ層実装** | SQLiteでNoSQL風操作を実装 | - 軽量<br>- 設定不要<br>- ファイルベース | - DynamoDB APIと非互換<br>- 開発工数増 | ⭐⭐ |
| **AWS DynamoDB（実環境）** | 開発用テーブル使用 | - 完全互換<br>- 設定不要 | - ネットワーク必要<br>- コスト発生 | ⭐⭐⭐⭐ |

#### DynamoDB Local セットアップ例
```bash
# DynamoDB Local ダウンロード
wget https://s3.ap-northeast-1.amazonaws.com/dynamodb-local-tokyo/dynamodb_local_latest.tar.gz
tar -xzf dynamodb_local_latest.tar.gz

# 起動
java -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar -sharedDb -port 8000
```

### 3.3 Aurora（PostgreSQL）の代替手段

| 代替手段 | 概要 | メリット | デメリット | 推奨度 |
|----------|------|----------|-----------|---------|
| **PostgreSQL（ローカル）** | ネイティブPostgreSQLインストール | - Aurora互換<br>- 高性能<br>- 開発環境定番 | - インストール・設定必要<br>- サービス管理が必要 | ⭐⭐⭐⭐⭐ |
| **SQLite** | ファイルベース軽量DB | - 設定不要<br>- 軽量<br>- ファイルベース | - PostgreSQL機能制限<br>- 同時アクセス制限 | ⭐⭐⭐ |
| **AWS Aurora（実環境）** | 開発用クラスター使用 | - 完全互換<br>- サーバーレス対応 | - ネットワーク必要<br>- 高コスト | ⭐⭐ |

#### PostgreSQL セットアップ例（Ubuntu/WSL）
```bash
sudo apt update
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql
sudo systemctl enable postgresql

# データベース作成
sudo -u postgres createdb csvbatch_dev
```

### 3.4 Lambda関数の代替実行手段

| 代替手段 | 概要 | メリット | デメリット | 推奨度 |
|----------|------|----------|-----------|---------|
| **SAM CLI Local** | SAMによるローカル実行 | - Lambda環境に近い<br>- API Gateway模擬<br>- デバッグ機能 | - SAM CLI必要<br>- 起動時間かかる | ⭐⭐⭐⭐⭐ |
| **Node.js直接実行** | Lambda関数を直接実行 | - 高速<br>- デバッグ容易<br>- 設定不要 | - Lambda環境と差異<br>- AWS SDK設定必要 | ⭐⭐⭐⭐ |
| **AWS Lambda（実環境）** | 開発用関数デプロイ | - 完全互換<br>- 実環境テスト | - デプロイ時間<br>- ネットワーク必要 | ⭐⭐⭐ |

## 4. Lambda関数呼び出し方法

### 4.1 SAM CLI使用（推奨）

#### API Gateway模擬での呼び出し
```bash
# 1. SAMアプリケーション起動
sam local start-api --port 3000 --env-vars env.json

# 2. 環境変数設定ファイル（env.json）
{
  "CsvProcessorFunction": {
    "DYNAMODB_TABLE": "csv_audit_logs_local",
    "AURORA_ENDPOINT": "localhost:5432",
    "S3_BUCKET_PREFIX": "local-s3"
  }
}

# 3. CSV検証処理呼び出し
curl -X POST http://localhost:3000/process-csv \
  -H "Content-Type: application/json" \
  -d '{
    "eventType": "CSV_VALIDATION",
    "s3Bucket": "local-s3",
    "s3Key": "input-files/sample.csv",
    "chunkSize": 1000
  }'

# 4. チャンク処理呼び出し
curl -X POST http://localhost:3000/process-csv \
  -H "Content-Type: application/json" \
  -d '{
    "eventType": "CSV_CHUNK_PROCESSING",
    "s3Bucket": "local-s3",
    "s3Key": "input-files/sample.csv",
    "chunkIndex": 0,
    "chunkSize": 1000
  }'
```

#### 直接Lambda関数呼び出し
```bash
# 1. イベントファイル作成（validation-event.json）
{
  "eventType": "CSV_VALIDATION",
  "s3Bucket": "local-s3",
  "s3Key": "input-files/sample.csv",
  "chunkSize": 1000,
  "requestId": "test-request-001"
}

# 2. Lambda関数直接呼び出し
sam local invoke CsvProcessorFunction \
  --event validation-event.json \
  --env-vars env.json

# 3. チャンク処理イベント（chunk-event.json）
{
  "eventType": "CSV_CHUNK_PROCESSING",
  "s3Bucket": "local-s3",
  "s3Key": "input-files/sample.csv",
  "chunkIndex": 0,
  "chunkSize": 1000,
  "chunkData": [
    {"id": 1, "name": "Sample1", "value": 100},
    {"id": 2, "name": "Sample2", "value": 200}
  ]
}

sam local invoke CsvProcessorFunction --event chunk-event.json
```

### 4.2 Node.js直接実行

```bash
# 1. Lambda関数を直接実行
node -e "
const handler = require('./src/index').handler;
const event = {
  eventType: 'CSV_VALIDATION',
  s3Bucket: 'local-s3',
  s3Key: 'input-files/sample.csv',
  chunkSize: 1000
};
const context = {
  awsRequestId: 'local-test-001',
  getRemainingTimeInMillis: () => 300000
};
handler(event, context).then(result => {
  console.log('Result:', JSON.stringify(result, null, 2));
}).catch(error => {
  console.error('Error:', error);
});
"

# 2. TypeScript版実行（ts-nodeを使用）
npx ts-node -e "
import { handler } from './src/index';
const event = {
  eventType: 'CSV_VALIDATION' as const,
  s3Bucket: 'local-s3',
  s3Key: 'input-files/sample.csv'
};
handler(event, {} as any).then(console.log);
"
```

### 4.3 バッチスクリプトでの連続実行

```bash
#!/bin/bash
# batch-test.sh - Step Functions代替のバッチ処理

CSV_FILE="input-files/large-file.csv"
CHUNK_SIZE=1000

echo "=== CSV Batch Processing Test ==="

# 1. CSV検証
echo "Step 1: Validating CSV..."
VALIDATION_RESULT=$(curl -s -X POST http://localhost:3000/process-csv \
  -H "Content-Type: application/json" \
  -d "{
    \"eventType\": \"CSV_VALIDATION\",
    \"s3Bucket\": \"local-s3\",
    \"s3Key\": \"$CSV_FILE\",
    \"chunkSize\": $CHUNK_SIZE
  }")

echo "Validation Result: $VALIDATION_RESULT"

# JSONから総チャンク数を取得
TOTAL_CHUNKS=$(echo $VALIDATION_RESULT | jq -r '.totalChunks')

if [ "$TOTAL_CHUNKS" = "null" ]; then
  echo "Validation failed. Exiting."
  exit 1
fi

echo "Total chunks to process: $TOTAL_CHUNKS"

# 2. 並列チャンク処理
echo "Step 2: Processing chunks..."
for i in $(seq 0 $((TOTAL_CHUNKS-1))); do
  echo "Processing chunk $i/$((TOTAL_CHUNKS-1))..."
  
  curl -s -X POST http://localhost:3000/process-csv \
    -H "Content-Type: application/json" \
    -d "{
      \"eventType\": \"CSV_CHUNK_PROCESSING\",
      \"s3Bucket\": \"local-s3\",
      \"s3Key\": \"$CSV_FILE\",
      \"chunkIndex\": $i,
      \"chunkSize\": $CHUNK_SIZE
    }" &
    
  # 同時実行数制限（例：5並列）  
  if (( $i % 5 == 4 )); then
    wait
  fi
done

wait # 全ての並列処理完了を待機

# 3. 結果集約
echo "Step 3: Aggregating results..."
AGGREGATION_RESULT=$(curl -s -X POST http://localhost:3000/process-csv \
  -H "Content-Type: application/json" \
  -d "{
    \"eventType\": \"RESULT_AGGREGATION\",
    \"s3Bucket\": \"local-s3\",
    \"s3Key\": \"$CSV_FILE\",
    \"totalChunks\": $TOTAL_CHUNKS
  }")

echo "Aggregation Result: $AGGREGATION_RESULT"
echo "=== Batch Processing Completed ==="
```

### 4.4 その他の呼び出し方法

#### AWS CLI使用（実環境テスト時）
```bash
# Lambda関数呼び出し
aws lambda invoke \
  --function-name csv-processor-function \
  --payload '{
    "eventType": "CSV_VALIDATION",
    "s3Bucket": "csv-input-files-526636471122",
    "s3Key": "test/sample.csv"
  }' \
  --cli-binary-format raw-in-base64-out \
  response.json

cat response.json | jq '.'
```

#### Postmanコレクション
```json
{
  "info": {
    "name": "CSV Processor Local API",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
  },
  "item": [
    {
      "name": "CSV Validation",
      "request": {
        "method": "POST",
        "header": [
          {
            "key": "Content-Type",
            "value": "application/json"
          }
        ],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"eventType\": \"CSV_VALIDATION\",\n  \"s3Bucket\": \"local-s3\",\n  \"s3Key\": \"input-files/sample.csv\",\n  \"chunkSize\": 1000\n}"
        },
        "url": {
          "raw": "http://localhost:3000/process-csv",
          "protocol": "http",
          "host": ["localhost"],
          "port": "3000",
          "path": ["process-csv"]
        }
      }
    }
  ]
}
```

## 5. 推奨構成

### 5.1 最適なローカル開発環境構成

```
ローカル開発環境/
├── local-s3/                    # S3代替（ローカルファイルシステム）
│   ├── input-files/
│   ├── processed-files/
│   └── error-files/
├── postgresql/                  # Aurora代替（PostgreSQL）
│   └── init-scripts/
├── dynamodb-local/              # DynamoDB Local
│   └── data/
├── sam-lambda/                  # Lambda関数（SAM）
│   ├── src/
│   ├── template.yaml
│   └── env.json
└── scripts/
    ├── start-local-env.sh       # 環境起動スクリプト
    ├── batch-test.sh            # バッチテストスクリプト
    └── cleanup.sh               # 環境クリーンアップ
```

### 5.2 環境起動スクリプト例

```bash
#!/bin/bash
# start-local-env.sh

echo "Starting local development environment..."

# 1. PostgreSQL起動確認
if ! pgrep -x "postgres" > /dev/null; then
  echo "Starting PostgreSQL..."
  sudo systemctl start postgresql
fi

# 2. DynamoDB Local起動
if ! pgrep -f "DynamoDBLocal" > /dev/null; then
  echo "Starting DynamoDB Local..."
  cd dynamodb-local
  nohup java -Djava.library.path=./DynamoDBLocal_lib \
    -jar DynamoDBLocal.jar -sharedDb -port 8000 > dynamodb.log 2>&1 &
  cd ..
fi

# 3. SAM Local API起動
echo "Starting SAM Local API..."
cd sam-lambda
sam local start-api --port 3000 --env-vars env.json &
cd ..

echo "Local environment started!"
echo "- PostgreSQL: localhost:5432"
echo "- DynamoDB Local: http://localhost:8000"
echo "- Lambda API: http://localhost:3000"
```

## 6. まとめ

### 6.1 Docker代替可能性
**結論: 完全に代替可能**

すべてのAWSサービスについて、Dockerを使用せずにローカル開発環境を構築することが可能です。

### 6.2 推奨構成
1. **S3**: ローカルファイルシステム（開発初期）→ MinIO（統合テスト）
2. **DynamoDB**: DynamoDB Local（JAR版）
3. **Aurora**: PostgreSQL（ローカルインストール）
4. **Lambda**: SAM CLI Local
5. **Step Functions**: バッチスクリプト + curl

### 6.3 開発効率化のポイント
- **SAM CLI**を中心とした開発環境構築
- **バッチスクリプト**でStep Functions代替
- **環境変数**での設定切り替え
- **段階的移行**（ローカル → ローカル+AWS → フルAWS）

この構成により、Docker環境を構築することなく、効率的なローカル開発が可能になります。